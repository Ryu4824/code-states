{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ryu4824/code-states/blob/main/%08n223_discussion_9%EC%A1%B0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **프로젝트 피드백**\n",
        "    \n",
        "    프로젝트에서 기술 사용 이상으로 중요한 것은 설득력 있는 스토리텔링으로, 명확히 문제를 정의하고 의미있는 인사이트를 도출할 수 있어야 합니다.\n",
        "    \n",
        "    오늘 디스커션에서는 주어진 예시 프로젝트에 대해 critical feedback을 해보세요. 이를 통해 문제 정의와 논리적인 스토리텔링에 대해 고민하는 시간을 가져보시기 바랍니다. \n",
        "    \n",
        "    🛫 [항공권 가격예측](https://www.notion.so/4305db333a2b4562829ad16a96ab6472)\n",
        "    \n",
        "    - 다음 질문에 답하며 인상적인 점, 개선할 점을 찾아 피드백 해보세요.\n",
        "        - 풀고자하는 문제가 무엇인가요? 명확하게 정의가 되었나요?\n",
        "        - 해당 문제를 푸는 것이 비즈니스적인 관점에서 어떤 가치가 있는지 설명이 되어있나요? 설명이 되어 있다면 설득력이 있는 주장인가요?\n",
        "        - 문제를 해결하기 위한 적절한 가설이 제시되었나요? 가설의 근거가 충분히 제시되었나요?\n",
        "        - 머신러닝 워크플로우가 이해하기 쉽게 제시되었나요?\n",
        "        - 가설이 해소가 되었나요?\n",
        "        - 모델 해석의 결과로 향후 비즈니스 전략을 세울 수 있는 actionable한 인사이트가 도출이 되었나요?\n",
        "        - 문제 정의, EDA, 모델링, 가설 해결, 인사이트 도출이 논리적으로 일관적인가요?\n"
      ],
      "metadata": {
        "id": "MOzdf27pqP2k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **피드백**\n",
        "\n",
        "1. 풀고자 하는 문제는 무엇인가, 명확하게 정의가 되었나요?\n",
        "  * **답변 :  명확하게 정의가 되었다고 봅니다. 단 하나의 노선만 이용하여 수익성을 최대로 할 수 있는 방법은 무엇인가 라는 문제입니다**\n",
        "\n",
        "2. 해당 문제를 푸는 것이 비즈니스적인 관점에서 어떤 가치가 있는지 설명이 되어있나요? 설명이 되어 있다면 설득력이 있는 주장인가요?\n",
        "  * **답변 : 항공권 가격에 영향을 미치는 가설을 설정하여 분석을 통해 나오게 될 결과값이 앞으로 해야할 비즈니스에 대한 방향성을 제시할 수 있을거라 봅니다.**\n",
        "\n",
        "3. 문제를 해결하기 위한 적절한 가설이 제시되었나요? 가설의 근거가 충분히 제시되었나요?\n",
        "  * **답변 : 가격을 초점으로 하여 경쟁력 있는 가격대가 어디인지 찾기위한 가설을 제시했다고 봅니다.**\n",
        "\n",
        "4. 머신러닝 워크플로우가 이해하기 쉽게 제시되었나요?\n",
        "  * **답변 : eda 및 분석 방법에 대해서는 적절한 방법 및 순서가 맞게 진행되었습니다.**\n",
        "\n",
        "5. 가설이 해소가 되었나요?\n",
        "  * **답변 :  항공시간과 항공 스케줄이 영향을 미치는지에 대한 가설을 설명했습니다. 다만 route에 대한 부분은 명확하지 않습니다.**\n",
        "\n",
        "6. 모델 해석의 결과로 향후 비즈니스 전략을 세울 수 있는 actionable한 인사이트가 도출이 되었나요?\n",
        "  * **답변 : 스케줄은 최소한 20일 이내로 편성하고 저가항공을 런칭해야하며 노선은 Kolkata 으로 해야하는 점이 도출됐습니다. 다만 왜 Hyderabad_Kolkata 항로 노선으로 해야하는지 명확하지는 않습니다.** \n",
        "\n",
        "7. 문제 정의, EDA, 모델링, 가설 해결, 인사이트 도출이 논리적으로 일관적인가요?\n",
        "  * **답변 :  티켓 가격을 정하기 위해 소비자들이 항공권을 구매하는 기간과 항공시간에 대한 연관을 잘 설명했다고 봅니다.**\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Ox3YtejGrBUL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "-----------------------------------------------------------------------------------------------------------------------------------------------\n",
        "\n"
      ],
      "metadata": {
        "id": "CAgMEI1-r259"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "--------------------------------------------------------------------------------------------------------------"
      ],
      "metadata": {
        "id": "vq_U0qOfr2sJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 심화 Topic (optional)\n",
        "    \n",
        "    GBDT와 같은 Tree-based Model에서 특성의 scaling이나 normalization이 필요하지 않은 이유는 무엇일까요? \n",
        "    \n",
        "    - 제시된 코드를 이용해서 `StandardScaler()` 를 적용했을 때와 적용하지 않았을 때의 결과를 비교해보세요.\n",
        "    - `StandardScaler()` 외에 다른 스케일 방법을 적용해도 결과가 같은지 확인해보세요.\n",
        "        - MinMaxScaler, RobustScaler 등\n",
        "        - Scaler의 수식을 이해하려고 하기보다는 다양한 Scaler를 사용해보는 것에 초점을 맞춰보세요.\n",
        "    - 이유를 설명해보세요.\n",
        "    - 코드"
      ],
      "metadata": {
        "id": "lsmPQ7CUry-H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**GBDT와 같은 Tree-based Model에서 특성의 scaling이나 normalization이 필요하지 않은 이유는 무엇일까요?**\n",
        "\n"
      ],
      "metadata": {
        "id": "p3lyKtP55CZj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nexakkpfqLbg",
        "outputId": "663f9b5b-27f9-426f-af09-672da523ec20"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting category_encoders\n",
            "  Downloading category_encoders-2.6.0-py2.py3-none-any.whl (81 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.2/81.2 KB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: patsy>=0.5.1 in /usr/local/lib/python3.9/dist-packages (from category_encoders) (0.5.3)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.9/dist-packages (from category_encoders) (1.22.4)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from category_encoders) (1.10.1)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.9/dist-packages (from category_encoders) (1.2.2)\n",
            "Requirement already satisfied: statsmodels>=0.9.0 in /usr/local/lib/python3.9/dist-packages (from category_encoders) (0.13.5)\n",
            "Requirement already satisfied: pandas>=1.0.5 in /usr/local/lib/python3.9/dist-packages (from category_encoders) (1.4.4)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas>=1.0.5->category_encoders) (2022.7.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.9/dist-packages (from pandas>=1.0.5->category_encoders) (2.8.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.9/dist-packages (from patsy>=0.5.1->category_encoders) (1.16.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn>=0.20.0->category_encoders) (3.1.0)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from scikit-learn>=0.20.0->category_encoders) (1.1.1)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.9/dist-packages (from statsmodels>=0.9.0->category_encoders) (23.0)\n",
            "Installing collected packages: category_encoders\n",
            "Successfully installed category_encoders-2.6.0\n"
          ]
        }
      ],
      "source": [
        "!pip install category_encoders\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from category_encoders import OneHotEncoder, OrdinalEncoder\n",
        "from sklearn.impute import SimpleImputer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#데이터 로딩\n",
        "target = 'vacc_h1n1_f'\n",
        "train = pd.merge(pd.read_csv('https://ds-lecture-data.s3.ap-northeast-2.amazonaws.com/vacc_flu/train.csv'), \n",
        "                 pd.read_csv('https://ds-lecture-data.s3.ap-northeast-2.amazonaws.com/vacc_flu/train_labels.csv')[target], left_index=True, right_index=True)\n",
        "\n",
        "#원래 검증 데이터셋을 분리해야하지만, 단순히 스케일러의 예시만을 위해 사용하기 때문에 분리하지 않았습니다.\n",
        "#실제로 모델링을 할 경우 꼭 검증 데이터셋을 분리해야합니다.\n",
        "y_train = train.pop(target)\n",
        "X_train = train\n",
        "X_train.shape, y_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SVVIwOn0qWxy",
        "outputId": "3aee5901-4eb5-4c09-d823-c9123aa63ec7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((42154, 38), (42154,))"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. MinMaxScaler: 특성의 최솟값과 최댓값을 사용하여 모든 특성을 0과 1 사이로 조정합니다.\n",
        "\n",
        "2. RobustScaler: 중앙값과 IQR(Interquartile Range)을 사용하여 특성의 스케일을 조정합니다. 이 방법은 이상치(outlier)가 있는 데이터셋에서 유용합니다.\n",
        "\n",
        "3. MaxAbsScaler: 특성의 최댓값의 절대값을 사용하여 모든 특성을 -1과 1 사이로 조정합니다. 이 방법은 데이터셋에 음수 값이 있을 때 유용합니다.\n",
        "\n",
        "4. PowerTransformer: 데이터셋의 분포를 조정하여 특성의 스케일을 조정합니다. 이 방법은 데이터셋의 분포가 비대칭일 때 유용합니다."
      ],
      "metadata": {
        "id": "cGOrDITW3kR5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Scaler가 없을 때 학습\n",
        "pipe2 = make_pipeline(OrdinalEncoder(),\n",
        "                     SimpleImputer(),\n",
        "\t\t\t\t\t\t\t\t\t\t # Scaler가 없을 때\n",
        "                     DecisionTreeClassifier(random_state = 42))\n",
        "\n",
        "pipe2.fit(X_train, y_train)\n",
        "\n",
        "#정확도 확인\n",
        "print(pipe2.score(X_train, y_train))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yKbLQjzgqaUr",
        "outputId": "d1449358-5445-4d16-e592-7c2a485e1bb9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.996844902025905\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# MinMaxScaler Scaler가 있을 때 학습\n",
        "pipe = make_pipeline(OrdinalEncoder(),\n",
        "                     SimpleImputer(),\n",
        "                     # MinMaxScaler Scaler 시작\n",
        "                     MinMaxScaler(),\n",
        "                     # Scaler 끝\n",
        "                     DecisionTreeClassifier(random_state = 42))\n",
        "\n",
        "pipe.fit(X_train, y_train)\n",
        "\n",
        "#정확도 확인\n",
        "print(pipe.score(X_train, y_train))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1hgdPehMqYW3",
        "outputId": "308f96ec-8407-43b3-ef1b-bac4d2b86933"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.996844902025905\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# RobustScale Scaler가 있을 때 학습\n",
        "pipe = make_pipeline(OrdinalEncoder(),\n",
        "                     SimpleImputer(),\n",
        "                     # RobustScaler Scaler 시작\n",
        "                     RobustScaler(),\n",
        "                     # Scaler 끝\n",
        "                     DecisionTreeClassifier(random_state = 42))\n",
        "\n",
        "pipe.fit(X_train, y_train)\n",
        "\n",
        "#정확도 확인\n",
        "print(pipe.score(X_train, y_train))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zP7euE-T4L-r",
        "outputId": "876d431e-87ad-4203-d205-e7cd50f9a63b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.996844902025905\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# MaxAbsScaler Scaler가 있을 때 학습\n",
        "from sklearn.preprocessing import MaxAbsScaler\n",
        "\n",
        "pipe = make_pipeline(OrdinalEncoder(),\n",
        "                     SimpleImputer(),\n",
        "                     # MaxAbsScaler Scaler 시작\n",
        "                     MaxAbsScaler(),\n",
        "                     # Scaler 끝\n",
        "                     DecisionTreeClassifier(random_state = 42))\n",
        "\n",
        "pipe.fit(X_train, y_train)\n",
        "\n",
        "#정확도 확인\n",
        "print(pipe.score(X_train, y_train))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8LjWx_0c4QVW",
        "outputId": "b3ca1587-9b56-4476-b24d-2fb07f9b8717"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.996844902025905\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# PowerTransformer Scaler가 있을 때 학습\n",
        "from sklearn.preprocessing import PowerTransformer\n",
        "\n",
        "pipe = make_pipeline(OrdinalEncoder(),\n",
        "                     SimpleImputer(),\n",
        "                     # PowerTransformer Scaler 시작\n",
        "                     PowerTransformer(),\n",
        "                     # Scaler 끝\n",
        "                     DecisionTreeClassifier(random_state = 42))\n",
        "\n",
        "pipe.fit(X_train, y_train)\n",
        "\n",
        "#정확도 확인\n",
        "print(pipe.score(X_train, y_train))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cU1U6fDo4vq0",
        "outputId": "a007bb6c-adf5-471f-f830-18687c7cf40f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.996844902025905\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*** 결론**\n",
        "\n",
        "\n",
        "GBDT와 같은 Tree-based Model에서는 특성의 scaling이나 normalization이 필요하지 않습니다.\n",
        "\n",
        "이는 트리 기반 모델이 특성의 스케일링에 민감하지 않기 때문입니다.\n",
        "\n",
        "트리 기반 모델은 각 노드에서 특정 특성을 선택하여 분할하는 방식으로 작동합니다. \n",
        "\n",
        "이때 특성의 스케일이 달라져도 해당 특성이 분할에 사용되는 기준값(threshold)도 그에 맞게 조정되기 때문에 결과적으로 모델의 예측 성능에 큰 영향을 미치지 않습니다.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "7rhhMTCe6wxm"
      }
    }
  ]
}